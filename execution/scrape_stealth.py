import sys
import os
import json
from datetime import datetime
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from directives.scrape_banners_stealth import scrape_website_banners_stealth

def save_results(url, banners, location):
    """Save scraping results to a JSON file"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"banner_results_{timestamp}.json"
    
    data = {
        'url': url,
        'location': location,
        'timestamp': datetime.now().isoformat(),
        'total_banners': len(banners),
        'banners': banners
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Results saved to: {filename}")

def main():
    """Main execution function for stealth scraping"""
    
    # Interactive mode
    if len(sys.argv) < 2:
        print("\n" + "=" * 70)
        print("     üïµÔ∏è  STEALTH Banner Image Scraper (Advanced Version)")
        print("=" * 70)
        
        # Get URL
        url = input("\nüåê Enter website URL: ").strip()
        
        if not url:
            print("‚ùå Error: URL cannot be empty")
            sys.exit(1)
        
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        # Show locations
        print("\nüìç Available Locations:")
        print("  1. üá∫üá∏ US - United States (San Francisco)")
        print("  2. üá¨üáß UK - United Kingdom (London)")
        print("  3. üá©üá™ DE - Germany (Berlin)")
        print("  4. üá´üá∑ FR - France (Paris)")
        print("  5. üáØüáµ JP - Japan (Tokyo)")
        print("  6. üá¶üá∫ AU - Australia (Sydney)")
        print("  7. üá®üá¶ CA - Canada (Toronto)")
        print("  8. üáßüá∑ BR - Brazil (S√£o Paulo)")
        print("  9. üáÆüá≥ IN - India (New Delhi)")
        print(" 10. üá∏üá¨ SG - Singapore")
        
        location_input = input("\nüó∫Ô∏è  Select location (1-10 or country code, default: US): ").strip().upper()
        
        location_map = {
            '1': 'US', '2': 'UK', '3': 'DE', '4': 'FR', '5': 'JP',
            '6': 'AU', '7': 'CA', '8': 'BR', '9': 'IN', '10': 'SG'
        }
        
        if location_input in location_map:
            location = location_map[location_input]
        elif location_input in ['US', 'UK', 'DE', 'FR', 'JP', 'AU', 'CA', 'BR', 'IN', 'SG']:
            location = location_input
        else:
            location = 'US'
            print(f"‚ÑπÔ∏è  Using default: US")
        
        # Browser visibility
        visible_input = input("\nüëÅÔ∏è  Show browser window? (y/n, default: n): ").strip().lower()
        headless = visible_input not in ['y', 'yes']
        
        # Proxy option
        proxy_input = input("\nüîí Use proxy? Enter proxy URL or press Enter to skip: ").strip()
        proxy = proxy_input if proxy_input else None
        
        # Save results option
        save_input = input("\nüíæ Save results to file? (y/n, default: y): ").strip().lower()
        save_results_option = save_input not in ['n', 'no']
        
    else:
        print("Usage: Just run the script without arguments for interactive mode")
        print("Example: py execution\\scrape_stealth.py")
        sys.exit(1)
    
    print("\n" + "=" * 70)
    print("     üïµÔ∏è  STEALTH Banner Image Scraper")
    print("=" * 70)
    print(f"\nüéØ Target URL: {url}")
    print(f"üó∫Ô∏è  Location: {location}")
    print(f"üëÅÔ∏è  Mode: {'Visible Browser' if not headless else 'Headless (Hidden)'}")
    if proxy:
        print(f"üîí Proxy: {proxy}")
    print("\n‚è≥ This may take 15-45 seconds depending on the website...")
    print("   Using advanced stealth techniques to avoid detection...")
    print("-" * 70 + "\n")
    
    # Scrape the website
    try:
        banners = scrape_website_banners_stealth(
            url, 
            headless=headless, 
            location=location,
            proxy=proxy
        )
        
        print("\n" + "=" * 70)
        
        if banners:
            print(f"\n‚úÖ SUCCESS! Found {len(banners)} banner image(s)!\n")
            
            for i, banner in enumerate(banners, 1):
                print(f"üì∏ Banner #{i}: {banner['type']}")
                print(f"   üîó URL: {banner['src'][:100]}{'...' if len(banner['src']) > 100 else ''}")
                print(f"   üìù Alt: {banner['alt'][:60]}{'...' if len(banner['alt']) > 60 else ''}")
                print(f"   üìê Size: {banner['width']} x {banner['height']}px")
                print()
            
            # Save results if requested
            if save_results_option:
                save_results(url, banners, location)
        else:
            print("\n‚ö†Ô∏è  No banner images found on this website.\n")
            print("Possible reasons:")
            print("  ‚Ä¢ The website has no banner images")
            print("  ‚Ä¢ The website uses advanced bot detection")
            print("  ‚Ä¢ Images are loaded via complex JavaScript")
            print("  ‚Ä¢ Try using --visible mode to see what's happening")
            print("  ‚Ä¢ Try a different location")
        
        print("=" * 70 + "\n")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Scraping cancelled by user.")
        sys.exit(0)
    except Exception as e:
        print(f"\n‚ùå Error occurred: {e}")
        print("\nTroubleshooting:")
        print("  1. Make sure Playwright is installed: py -m pip install playwright")
        print("  2. Make sure browsers are installed: py -m playwright install chromium")
        print("  3. Check your internet connection")
        print("  4. Try with --visible mode to debug")
        sys.exit(1)

if __name__ == "__main__":
    main()